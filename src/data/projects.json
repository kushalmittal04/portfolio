
[
  {
    "id": 1,
    "slug": "generative-ai-portfolio",
    "name": "Generative AI Portfolio Website",
    "tagline": "A dynamic personal portfolio built with Next.js and Generative AI.",
    "overview": "This project is a modern, fully responsive portfolio website created using Next.js, React, and Tailwind CSS. It leverages the power of Google's Gemini Pro through Genkit to enable conversational edits and content updates, demonstrating a novel approach to website management. The entire user interface, data structure, and layout were designed and implemented by the AI.",
    "features": [
      "Fully responsive design for all devices.",
      "Built with Next.js App Router for optimal performance.",
      "Styled with Tailwind CSS and ShadCN UI components.",
      "Integrated with Genkit for AI-powered conversational development.",
      "Dynamic data-driven content from JSON files."
    ],
    "challenges": [
      {
        "challenge": "Structuring the entire application code and data schemas from scratch via AI prompts.",
        "solution": "Iteratively defined types and components, guiding the AI to build a modular and scalable architecture."
      },
      {
        "challenge": "Ensuring the AI could correctly modify and update complex, multi-file code structures.",
        "solution": "Developed a robust XML-based change format that the AI could generate and the system could parse, ensuring atomic and accurate file updates."
      }
    ],
    "technologies": ["Next.js", "React", "Tailwind CSS", "Genkit", "TypeScript", "Vercel"],
    "skills": ["Full-Stack Development", "AI Integration", "Prompt Engineering", "UI/UX Design"],
    "githubUrl": "https://github.com/kushalmittal04/my-portfolio",
    "liveUrl": "https://kushalmittal.framer.website/",
    "images": [
      { "url": "https://picsum.photos/seed/101/1280/720", "dataAiHint": "website homepage" },
      { "url": "https://picsum.photos/seed/102/1280/720", "dataAiHint": "code snippet" },
      { "url": "https://picsum.photos/seed/103/1280/720", "dataAiHint": "project gallery" }
    ],
    "videoUrl": "https://www.youtube.com/embed/dQw4w9WgXcQ",
    "category": ["Web Application", "AI/ML"],
    "isFeatured": true
  },
  {
    "id": 2,
    "slug": "restaurant-name-generator",
    "name": "Restaurant Name & Menu Generator",
    "tagline": "AI-powered tool to generate creative restaurant names and menu ideas instantly.",
    "overview": "This AI-powered web app, built with LangChain and Streamlit, allows users to select a cuisine and instantly receive a creative restaurant name and AI-generated menu suggestions. It showcases the use of LLM chains and prompt engineering for a fun, interactive experience.",
    "features": [
      "Generates unique restaurant names based on cuisine.",
      "Suggests multiple cuisine-specific menu items.",
      "Interactive Streamlit web app.",
      "Uses LangChain SequentialChain for multi-step AI reasoning."
    ],
    "challenges": [
      {
        "challenge": "Designing prompts for consistent and creative names.",
        "solution": "Applied prompt engineering techniques to refine outputs."
      },
      {
        "challenge": "Managing API key security in a web application.",
        "solution": "Used dotenv to load environment variables securely."
      }
    ],
    "technologies": ["Python", "LangChain", "Streamlit", "Google Gemini API"],
    "skills": ["Prompt Engineering", "LLM Integration", "Web App Development"],
    "githubUrl": "https://github.com/kushalmittal04/restaurant_name_generator",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/201/1280/720", "dataAiHint": "restaurant menu" },
      { "url": "https://picsum.photos/seed/202/1280/720", "dataAiHint": "web app interface" }
    ],
    "videoUrl": "https://www.youtube.com/embed/LHJvOiIGtuc",
    "category": ["AI/ML", "Web Application"],
    "isFeatured": true
  },
  {
    "id": 3,
    "slug": "topic-qa-chatbot",
    "name": "Topic-Specific QA Chatbot",
    "tagline": "An AI-powered chatbot for answering FAQs with context-based retrieval.",
    "overview": "An intelligent, topic-specific assistant built with LangChain, Google Gemini API, and ChromaDB. It allows users to upload a document and ask questions, receiving accurate, context-driven answers. It uses embeddings for semantic search and a custom prompt to prevent hallucinations.",
    "features": [
      "Creates a local vector database from user-uploaded files.",
      "Retrieval-Augmented Generation (RAG) powered by LangChain.",
      "Uses HuggingFace embeddings for semantic search.",
      "Streamlit frontend for real-time chatbot interaction."
    ],
    "challenges": [
      {
        "challenge": "Preventing the chatbot from generating fabricated answers.",
        "solution": "Designed a strict custom prompt forcing the LLM to only use the provided context."
      },
      {
        "challenge": "Handling various document formats efficiently.",
        "solution": "Integrated loaders for PDF and text files."
      }
    ],
    "technologies": ["Python", "LangChain", "ChromaDB", "Streamlit", "HuggingFace"],
    "skills": ["Vector Databases", "RAG", "LLM Integration", "Prompt Engineering"],
    "githubUrl": "https://github.com/kushalmittal04/qa_chatbot",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/301/1280/720", "dataAiHint": "chatbot interface" },
      { "url": "https://picsum.photos/seed/302/1280/720", "dataAiHint": "data flow diagram" },
      { "url": "https://picsum.photos/seed/303/1280/720", "dataAiHint": "code terminal" }
    ],
    "videoUrl": "https://www.youtube.com/embed/gWiuK9U0s_A",
    "category": ["AI/ML", "Chatbot"],
    "isFeatured": true
  },
  {
    "id": 4,
    "slug": "customer-churn-prediction",
    "name": "Customer Churn Prediction",
    "tagline": "Predicting customer churn using supervised machine learning.",
    "overview": "A classic data science project to predict whether a customer will churn. The project involves data preprocessing, exploratory data analysis (EDA), feature engineering, and training several classification models (like Logistic Regression and Random Forest) to compare performance.",
    "features": [
      "EDA with Matplotlib and Seaborn.",
      "Feature scaling and encoding categorical variables.",
      "Model training and evaluation using Scikit-learn.",
      "Confusion matrix and classification report for performance analysis."
    ],
    "challenges": [
      {
        "challenge": "Dealing with an imbalanced dataset where churned customers are a minority.",
        "solution": "Applied techniques like SMOTE (Synthetic Minority Over-sampling Technique) to balance the classes."
      },
      {
        "challenge": "Interpreting model results to provide actionable business insights.",
        "solution": "Used feature importance plots to identify key drivers of churn."
      }
    ],
    "technologies": ["Python", "Pandas", "NumPy", "Scikit-learn", "Matplotlib", "Jupyter"],
    "skills": ["Machine Learning", "Data Analysis", "Classification Models", "Feature Engineering"],
    "githubUrl": "https://github.com/kushalmittal04/customer-churn-prediction",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/401/1280/720", "dataAiHint": "data chart" },
      { "url": "https://picsum.photos/seed/402/1280/720", "dataAiHint": "analytics dashboard" }
    ],
    "videoUrl": "https://www.youtube.com/embed/ETsekCVwps4",
    "category": ["Data Science", "Machine Learning"],
    "isFeatured": false
  },
  {
    "id": 5,
    "slug": "e-commerce-api",
    "name": "E-commerce REST API",
    "tagline": "A robust backend for a modern e-commerce platform.",
    "overview": "A complete RESTful API for an e-commerce application built with Node.js, Express, and MongoDB. The API supports user authentication, product management, order processing, and payment integration, following best practices for API design and security.",
    "features": [
      "JWT-based user authentication and authorization.",
      "CRUD operations for products, users, and orders.",
      "API documentation with Swagger/OpenAPI.",
      "Secure password hashing with bcrypt.",
      "Integration with Stripe for payment processing."
    ],
    "challenges": [
      {
        "challenge": "Designing a scalable and normalized database schema.",
        "solution": "Used Mongoose schemas with references to model relationships between users, products, and orders."
      },
      {
        "challenge": "Ensuring secure and protected API endpoints.",
        "solution": "Implemented middleware for token verification and role-based access control."
      }
    ],
    "technologies": ["Node.js", "Express.js", "MongoDB", "JWT", "Stripe", "Mongoose"],
    "skills": ["Backend Development", "REST APIs", "Database Design", "Authentication"],
    "githubUrl": "https://github.com/kushalmittal04/ecommerce-api",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/501/1280/720", "dataAiHint": "api code" },
      { "url": "https://picsum.photos/seed/502/1280/720", "dataAiHint": "database schema" },
      { "url": "https://picsum.photos/seed/503/1280/720", "dataAiHint": "network diagram" }
    ],
    "videoUrl": "https://www.youtube.com/embed/pQN-pn4_3gY",
    "category": ["Backend", "Web Application"],
    "isFeatured": false
  },
  {
    "id": 6,
    "slug": "real-time-chat-app",
    "name": "Real-Time Chat Application",
    "tagline": "A full-stack chat application using WebSockets.",
    "overview": "A web-based real-time chat application built with the MERN stack (MongoDB, Express, React, Node.js) and Socket.IO. Users can join rooms, send messages, and see who is currently active, all updated in real-time.",
    "features": [
      "Real-time messaging with Socket.IO.",
      "User authentication and session management.",
      "Ability to create and join different chat rooms.",
      "Display of active users in a room.",
      "Responsive frontend built with React and Material-UI."
    ],
    "challenges": [
      {
        "challenge": "Managing WebSocket connections and state efficiently on the server.",
        "solution": "Used Socket.IO's room feature to broadcast messages only to relevant clients."
      },
      {
        "challenge": "Updating the UI instantly across all clients without performance degradation.",
        "solution": "Leveraged React's state management and hooks to efficiently re-render components on new messages."
      }
    ],
    "technologies": ["React", "Node.js", "Express.js", "MongoDB", "Socket.IO", "Material-UI"],
    "skills": ["Full-Stack Development", "WebSockets", "Real-Time Communication"],
    "githubUrl": "https://github.com/kushalmittal04/real-time-chat-app",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/601/1280/720", "dataAiHint": "chat application" },
      { "url": "https://picsum.photos/seed/602/1280/720", "dataAiHint": "user interface" }
    ],
    "videoUrl": "https://www.youtube.com/embed/8N38An2s4y8",
    "category": ["Web Application", "Full-Stack"],
    "isFeatured": false
  },
  {
    "id": 7,
    "slug": "house-price-prediction",
    "name": "House Price Prediction Model",
    "tagline": "Predicting house prices with regression models.",
    "overview": "This project uses machine learning to predict house prices based on various features like location, size, and number of rooms. It involves comprehensive data cleaning, feature engineering, and the implementation of several regression models such as Linear Regression, Ridge, and Gradient Boosting.",
    "features": [
      "In-depth EDA to understand feature correlations.",
      "Handling of missing values and categorical data.",
      "Training and tuning multiple regression models.",
      "Evaluation using metrics like R-squared and RMSE."
    ],
    "challenges": [
      {
        "challenge": "Feature engineering from unstructured data like descriptions.",
        "solution": "Used NLP techniques like TF-IDF to convert text into numerical features."
      },
      {
        "challenge": "Avoiding overfitting with complex models.",
        "solution": "Applied regularization techniques (Ridge) and cross-validation."
      }
    ],
    "technologies": ["Python", "Pandas", "Scikit-learn", "XGBoost", "Jupyter Notebook"],
    "skills": ["Machine Learning", "Regression Analysis", "Data Science", "Feature Engineering"],
    "githubUrl": "https://github.com/kushalmittal04/house-price-prediction",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/701/1280/720", "dataAiHint": "house exterior" },
      { "url": "https://picsum.photos/seed/702/1280/720", "dataAiHint": "data graph" }
    ],
    "videoUrl": "https://www.youtube.com/embed/3LqWvYpB_yI",
    "category": ["Data Science", "Machine Learning"],
    "isFeatured": false
  },
  {
    "id": 8,
    "slug": "sentiment-analysis-api",
    "name": "Sentiment Analysis API",
    "tagline": "A REST API for analyzing the sentiment of text.",
    "overview": "A simple yet powerful REST API built with Flask that takes a piece of text and returns its sentiment (positive, negative, neutral) and a confidence score. The model is trained on a large dataset of reviews using TensorFlow/Keras and an LSTM network.",
    "features": [
      "Simple API endpoint to analyze text sentiment.",
      "Deep learning model (LSTM) for high accuracy.",
      "Built with Flask for a lightweight and fast backend.",
      "Easy to deploy using Docker."
    ],
    "challenges": [
      {
        "challenge": "Training an accurate sentiment model from scratch.",
        "solution": "Used pre-trained word embeddings (GloVe) to improve model performance and training speed."
      },
      {
        "challenge": "Packaging the model and API for easy deployment.",
        "solution": "Created a Dockerfile to containerize the Flask application and its dependencies."
      }
    ],
    "technologies": ["Python", "Flask", "TensorFlow", "Keras", "Docker"],
    "skills": ["NLP", "Deep Learning", "REST APIs", "Model Deployment"],
    "githubUrl": "https://github.com/kushalmittal04/sentiment-analysis-api",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/801/1280/720", "dataAiHint": "text analysis" },
      { "url": "https://picsum.photos/seed/802/1280/720", "dataAiHint": "server code" }
    ],
    "videoUrl": "https://www.youtube.com/embed/P2MX9o2LpDw",
    "category": ["AI/ML", "Backend"],
    "isFeatured": false
  },
  {
    "id": 9,
    "slug": "devops-cicd-pipeline",
    "name": "DevOps CI/CD Pipeline for Node.js",
    "tagline": "Automating the build, test, and deployment of a web app.",
    "overview": "This project demonstrates a complete CI/CD pipeline for a Node.js application using Jenkins, Docker, and GitHub. Every push to the GitHub repository automatically triggers Jenkins to build a Docker image, run tests, and deploy the application to a staging server.",
    "features": [
      "Automated pipeline triggered by GitHub webhooks.",
      "Jenkinsfile defining the build, test, and deploy stages.",
      "Dockerization of a Node.js application.",
      "Automated testing integration."
    ],
    "challenges": [
      {
        "challenge": "Configuring Jenkins and GitHub webhooks correctly.",
        "solution": "Used ngrok to expose the local Jenkins server for initial webhook testing and setup."
      },
      {
        "challenge": "Writing a reliable and reusable Jenkinsfile.",
        "solution": "Created a declarative pipeline script with separate stages for clarity and error handling."
      }
    ],
    "technologies": ["Jenkins", "Docker", "GitHub", "Node.js", "Groovy"],
    "skills": ["CI/CD", "DevOps", "Automation", "Containerization"],
    "githubUrl": "https://github.com/kushalmittal04/devops-cicd-pipeline",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/901/1280/720", "dataAiHint": "devops pipeline" },
      { "url": "https://picsum.photos/seed/902/1280/720", "dataAiHint": "flowchart diagram" }
    ],
    "videoUrl": "https://www.youtube.com/embed/J9-L-Y22qgQ",
    "category": ["DevOps"],
    "isFeatured": false
  },
  {
    "id": 10,
    "slug": "image-classification-cnn",
    "name": "Image Classification with CNN",
    "tagline": "Classifying images using a custom Convolutional Neural Network.",
    "overview": "A project focused on building, training, and evaluating a Convolutional Neural Network (CNN) from scratch using TensorFlow/Keras to classify images from the CIFAR-10 dataset. It covers data augmentation, model architecture design, and performance visualization.",
    "features": [
      "Custom CNN architecture design.",
      "Image data augmentation to prevent overfitting.",
      "Model training with callbacks for early stopping.",
      "Visualization of training history and confusion matrix."
    ],
    "challenges": [
      {
        "challenge": "Designing a CNN architecture that is deep enough to learn but not so complex it overfits.",
        "solution": "Started with a simple architecture and gradually added layers, using dropout for regularization."
      },
      {
        "challenge": "Long training times on a CPU.",
        "solution": "Utilized Google Colab's free GPU resources to accelerate model training significantly."
      }
    ],
    "technologies": ["Python", "TensorFlow", "Keras", "NumPy", "Matplotlib", "Google Colab"],
    "skills": ["Deep Learning", "Computer Vision", "CNNs", "Image Processing"],
    "githubUrl": "https://github.com/kushalmittal04/image-classification-cnn",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/1001/1280/720", "dataAiHint": "neural network" },
      { "url": "https://picsum.photos/seed/1002/1280/720", "dataAiHint": "image data" }
    ],
    "videoUrl": "https://www.youtube.com/embed/DbeIqrR8gBI",
    "category": ["AI/ML", "Deep Learning"],
    "isFeatured": false
  },
  {
    "id": 11,
    "slug": "serverless-contact-form",
    "name": "Serverless Contact Form API",
    "tagline": "A serverless backend for a website contact form.",
    "overview": "This project creates a serverless REST API using AWS Lambda and API Gateway to handle submissions from a website contact form. When a user submits the form, the API triggers a Lambda function that sends an email notification via Amazon SES (Simple Email Service).",
    "features": [
      "Cost-effective serverless architecture.",
      "API endpoint secured with API Gateway.",
      "Node.js Lambda function to process form data.",
      "Email notifications using AWS SES.",
      "Infrastructure as Code with AWS SAM/Serverless Framework."
    ],
    "challenges": [
      {
        "challenge": "Configuring IAM roles and permissions for Lambda and SES.",
        "solution": "Defined precise IAM policies to grant the Lambda function the minimum required permissions to call SES."
      },
      {
        "challenge": "Handling CORS for the front-end application.",
        "solution": "Enabled and configured CORS directly in the API Gateway settings."
      }
    ],
    "technologies": ["AWS Lambda", "API Gateway", "Amazon SES", "Node.js", "Serverless Framework"],
    "skills": ["Serverless", "Cloud Computing", "Backend Development", "AWS"],
    "githubUrl": "https://github.com/kushalmittal04/serverless-contact-form",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/1101/1280/720", "dataAiHint": "cloud architecture" },
      { "url": "https://picsum.photos/seed/1102/1280/720", "dataAiHint": "contact form" }
    ],
    "videoUrl": "https://www.youtube.com/embed/BS2Vr0y_f7s",
    "category": ["Cloud", "Backend"],
    "isFeatured": false
  },
  {
    "id": 12,
    "slug": "sales-data-dashboard",
    "name": "Sales Data Dashboard",
    "tagline": "An interactive dashboard for visualizing sales data.",
    "overview": "An interactive data dashboard built with Python's Dash and Plotly library. The dashboard allows users to filter sales data by region, product, and date range, with multiple charts (bar, pie, line) updating dynamically to provide insights into sales performance.",
    "features": [
      "Interactive dashboard with dropdowns and date pickers.",
      "Multiple linked charts for a holistic view.",
      "Built with Dash for a pure Python web framework.",
      "Data processing and aggregation with Pandas.",
      "Clean and professional UI design."
    ],
    "challenges": [
      {
        "challenge": "Making multiple graphs update based on a single set of filters efficiently.",
        "solution": "Used Dash's callback system with multiple outputs to trigger all graph updates from a single input change."
      },
      {
        "challenge": "Deploying the Dash application for public access.",
        "solution": "Containerized the app with Docker and deployed it on Heroku."
      }
    ],
    "technologies": ["Python", "Dash", "Plotly", "Pandas", "Docker", "Heroku"],
    "skills": ["Data Visualization", "Dashboarding", "Data Analysis", "Web App Development"],
    "githubUrl": "https://github.com/kushalmittal04/sales-data-dashboard",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/1201/1280/720", "dataAiHint": "analytics dashboard" },
      { "url": "https://picsum.photos/seed/1202/1280/720", "dataAiHint": "business charts" }
    ],
    "videoUrl": "https://www.youtube.com/embed/lYa_B-V2t2g",
    "category": ["Data Science", "Web Application"],
    "isFeatured": false
  },
  {
    "id": 13,
    "slug": "task-management-app",
    "name": "Task Management App",
    "tagline": "A full-stack Kanban-style task management application.",
    "overview": "A clone of Trello, this full-stack application is built with React (using `react-beautiful-dnd` for drag-and-drop), a Node.js/Express backend, and a PostgreSQL database. Users can create boards, lists, and cards, and drag them to reorder or move them between lists.",
    "features": [
      "Drag-and-drop functionality for tasks and lists.",
      "User authentication with Passport.js.",
      "RESTful API for managing boards, lists, and cards.",
      "Relational database schema with PostgreSQL.",
      "Modern frontend with React hooks and Context API."
    ],
    "challenges": [
      {
        "challenge": "Implementing smooth and performant drag-and-drop.",
        "solution": "Utilized the `react-beautiful-dnd` library, which is optimized for this exact purpose."
      },
      {
        "challenge": "Persisting the order of items in the database after a drag-and-drop action.",
        "solution": "Created a dedicated API endpoint to update the `position` or `rank` of items in the database in a single transaction."
      }
    ],
    "technologies": ["React", "Node.js", "Express.js", "PostgreSQL", "Sequelize", "Passport.js"],
    "skills": ["Full-Stack Development", "Database Design", "Drag and Drop", "UI/UX"],
    "githubUrl": "https://github.com/kushalmittal04/task-management-app",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/1301/1280/720", "dataAiHint": "kanban board" },
      { "url": "https://picsum.photos/seed/1302/1280/720", "dataAiHint": "project management" }
    ],
    "videoUrl": "https://www.youtube.com/embed/8tPnX7OPo0Q",
    "category": ["Web Application", "Full-Stack"],
    "isFeatured": false
  },
  {
    "id": 14,
    "slug": "code-documentation-generator",
    "name": "AI Code Documentation Generator",
    "tagline": "A tool that uses AI to automatically generate documentation for code.",
    "overview": "This project is a VS Code extension that leverages a fine-tuned language model to automatically generate documentation for Python functions. A developer can highlight a function, right-click, and the extension will call an API to get a well-formatted docstring explaining what the code does, its parameters, and what it returns.",
    "features": [
      "VS Code extension with context menu integration.",
      "API backend that serves a fine-tuned LLM.",
      "Automatically generates Python docstrings in a standard format (e.g., reST).",
      "Supports asynchronous code and complex function signatures."
    ],
    "challenges": [
      {
        "challenge": "Fine-tuning a language model to produce accurate and consistently formatted docstrings.",
        "solution": "Created a high-quality dataset of code-docstring pairs and used it to fine-tune a smaller, open-source LLM like CodeLlama."
      },
      {
        "challenge": "Developing and packaging a VS Code extension.",
        "solution": "Followed the official VS Code extension API documentation and used `vsce` to package the extension."
      }
    ],
    "technologies": ["Python", "FastAPI", "HuggingFace Transformers", "TypeScript", "VS Code API"],
    "skills": ["AI/ML", "LLM Fine-Tuning", "Developer Tools", "API Development"],
    "githubUrl": "https://github.com/kushalmittal04/code-documentation-generator",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/1401/1280/720", "dataAiHint": "code editor" },
      { "url": "https://picsum.photos/seed/1402/1280/720", "dataAiHint": "documentation example" }
    ],
    "videoUrl": "https://www.youtube.com/embed/DozTrSgEom0",
    "category": ["AI/ML", "Developer Tool"],
    "isFeatured": false
  },
  {
    "id": 15,
    "slug": "rera-projects-data-scraper",
    "name": "RERA Projects Data Scraper",
    "tagline": "Automated web scraping tool for real estate compliance data.",
    "overview": "RERA Scraper is a Python-based automation tool designed to collect structured data from the Real Estate Regulatory Authority (RERA) portal. It simplifies the process of retrieving property, agent, and project registration details, making it easier for analysts and researchers to work with real-estate data. The tool eliminates manual data entry by automating data collection, cleaning, and exporting into structured formats.",
    "features": [
      "Automated scraping of property & project details from the RERA portal.",
      "Handles pagination and multiple records efficiently.",
      "Data cleaning and formatting for improved readability.",
      "Robust error handling for missing or restricted data.",
      "Exports data to CSV/Excel for further analysis."
    ],
    "challenges": [
      {
        "challenge": "The RERA portal used dynamic loading and hidden elements.",
        "solution": "Used Selenium waits and advanced DOM traversal to reliably handle dynamic content."
      },
      {
        "challenge": "Large datasets caused performance issues during scraping.",
        "solution": "Implemented pagination handling and batched data exports to optimize memory usage."
      }
    ],
    "technologies": ["Python", "Selenium", "BeautifulSoup", "Pandas"],
    "skills": ["Web Scraping", "Data Extraction", "Data Cleaning", "Automation", "File Handling"],
    "githubUrl": "https://github.com/kushalmittal04/rera_scraper",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/1501/1280/720", "dataAiHint": "data scraping code" },
      { "url": "https://picsum.photos/seed/1502/1280/720", "dataAiHint": "data table" }
    ],
    "videoUrl": "https://www.youtube.com/embed/_a57UTiXiQQ",
    "category": ["Automation", "Data Scraping"],
    "isFeatured": false
  },
  {
    "id": 16,
    "slug": "agentic-research-assistant",
    "name": "Agentic AI Research Assistant",
    "tagline": "An AI agent that autonomously researches topics online.",
    "overview": "This project features an autonomous AI agent built with LangChain and LangGraph. The agent can take a research topic, break it down into sub-questions, browse the web to find information, and synthesize the findings into a coherent report. It demonstrates an agentic loop where the AI decides its own next steps.",
    "features": [
      "Autonomous research capabilities using web search tools.",
      "State management with LangGraph to orchestrate the research process.",
      "Uses function calling to interact with search APIs.",
      "Synthesizes information from multiple sources into a final summary."
    ],
    "challenges": [
      {
        "challenge": "Designing an agentic graph that can handle cycles and make decisions.",
        "solution": "Used LangGraph's state machine approach to allow the agent to loop, search, and decide when it has enough information."
      },
      {
        "challenge": "Preventing the agent from getting stuck in loops or going off-topic.",
        "solution": "Implemented a maximum number of iterations and a clear, concise prompt that defines the agent's goal and constraints."
      }
    ],
    "technologies": ["Python", "LangChain", "LangGraph", "Tavily API", "Google Gemini API"],
    "skills": ["Agentic AI", "Autonomous Systems", "LLM", "Graph-based State Machines"],
    "githubUrl": "https://github.com/kushalmittal04/agentic-research-assistant",
    "liveUrl": null,
    "images": [
      { "url": "https://picsum.photos/seed/1601/1280/720", "dataAiHint": "ai agent" },
      { "url": "https://picsum.photos/seed/1602/1280/720", "dataAiHint": "research report" }
    ],
    "videoUrl": "https://www.youtube.com/embed/5aIUnkPyC-Y",
    "category": ["AI/ML", "Agents"],
    "isFeatured": false
  }
]
