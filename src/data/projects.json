
[
  {
    "id": 1,
    "slug": "rera-scraper",
    "name": "RERA Projects Data Scraper",
    "tagline": "Automated web scraping tool for real estate compliance data.",
    "overview": "RERA Scraper is a Python-based automation tool designed to collect structured data from the Real Estate Regulatory Authority (RERA) portal. It simplifies the process of retrieving property, agent, and project registration details, making it easier for analysts and researchers to work with real-estate data. The tool eliminates manual data entry by automating data collection, cleaning, and exporting into structured formats.",
    "features": [
      "Automated scraping of property & project details from the RERA portal.",
      "Handles pagination and multiple records efficiently.",
      "Data cleaning and formatting for improved readability.",
      "Robust error handling for missing or restricted data.",
      "Exports data to CSV/Excel for further analysis."
    ],
    "challenges": [
      {
        "challenge": "The RERA portal used dynamic loading and hidden elements.",
        "solution": "Used Selenium waits and advanced DOM traversal to reliably handle dynamic content."
      },
      {
        "challenge": "Large datasets caused performance issues during scraping.",
        "solution": "Implemented pagination handling and batched data exports to optimize memory usage."
      },
      {
        "challenge": "Data fields were inconsistent across different state portals.",
        "solution": "Applied Pandas preprocessing to standardize the output schema for consistent data."
      }
    ],
    "technologies": [
      "Python",
      "Selenium",
      "BeautifulSoup",
      "Pandas"
    ],
    "skills": [
      "Web Scraping",
      "Data Extraction",
      "Data Cleaning",
      "Automation",
      "File Handling"
    ],
    "githubUrl": "https://github.com/kushalmittal04/rera_scraper",
    "liveUrl": null,
    "images": [
      {
        "url": "/images/projects/rera_scraper/screenshot1.png",
        "dataAiHint": "data scraping code"
      },
      {
        "url": "/images/projects/rera_scraper/screenshot2.png",
        "dataAiHint": "scraped data table"
      }
    ],
    "videoUrl": "https://www.youtube.com/embed/_a57UTiXiQQ",
    "category": [
      "Automation",
      "Data Scraping"
    ],
    "isFeatured": false
  },
  {
    "id": 2,
    "slug": "restaurant-name-generator",
    "name": "Restaurant Name & Menu Generator",
    "tagline": "AI-powered tool to generate creative restaurant names and menu ideas instantly.",
    "overview": "Restaurant Name Generator is an AI-powered web app built with LangChain, Streamlit, and Google Gemini API. It allows users to select a cuisine and instantly get a fancy restaurant name along with AI-generated menu suggestions. The project demonstrates the use of LLM chains, prompt engineering, and a simple Streamlit UI for interactive user experience.",
    "features": [
      "Generates a unique restaurant name based on the chosen cuisine.",
      "Suggests multiple cuisine-specific menu items automatically.",
      "Interactive Streamlit web app with sidebar selection.",
      "Uses LangChain SequentialChain for multi-step AI reasoning.",
      "Environment variable handling with dotenv for secure API keys."
    ],
    "challenges": [
      {
        "challenge": "Designing prompts to ensure consistent and precise restaurant names.",
        "solution": "Applied prompt engineering techniques and restricted outputs to single-name responses."
      },
      {
        "challenge": "Maintaining API security when using Gemini API keys.",
        "solution": "Used dotenv to load environment variables and keep credentials hidden."
      },
      {
        "challenge": "Ensuring a smooth user experience in Streamlit UI.",
        "solution": "Created a simple sidebar-based input with formatted AI responses."
      }
    ],
    "technologies": [
      "Python",
      "LangChain",
      "Streamlit",
      "Google Gemini API",
      "dotenv"
    ],
    "skills": [
      "Prompt Engineering",
      "LLM Integration",
      "Web App Development",
      "AI Automation"
    ],
    "githubUrl": "https://github.com/kushalmittal04/restaurant-name-generator",
    "liveUrl": null,
    "images": [
      {
        "url": "/images/projects/restaurant_name_generator/screenshot1.png",
        "dataAiHint": "Streamlit UI with generated restaurant name"
      },
      {
        "url": "/images/projects/restaurant_name_generator/screenshot2.png",
        "dataAiHint": "AI-generated menu items"
      }
    ],
    "videoUrl": "https://www.youtube.com/embed/LHJvOiIGtuc",
    "category": [
      "AI",
      "Web App",
      "LLM"
    ],
    "isFeatured": false
  },
  {
    "id": 3,
    "slug": "specific-qa-chatbot",
    "name": "Specific QA Chatbot",
    "tagline": "An AI-powered chatbot for answering FAQs with context-based retrieval.",
    "overview": "This QA Chatbot is an intelligent, topic-specific assistant built using LangChain, Google Gemini API, HuggingFace embeddings, and ChromaDB. It enables users to query a dataset of FAQs and receive accurate, context-driven answers. The system uses embeddings to create a searchable vector database and applies RetrievalQA with a custom prompt for reliable, non-hallucinated responses. The Streamlit frontend provides a simple and interactive interface for real-time Q&A.",
    "features": [
      "Creates a local vector database from FAQ CSV files.",
      "RetrievalQA powered by LangChain with Google Gemini LLM.",
      "Uses HuggingFace embeddings for semantic search.",
      "Streamlit frontend for real-time chatbot interaction.",
      "Ensures safe responses by avoiding fabricated answers."
    ],
    "challenges": [
      {
        "challenge": "Preventing the chatbot from generating hallucinated answers.",
        "solution": "Designed a strict custom prompt that forces the LLM to only use context or respond with 'I don't know.'"
      },
      {
        "challenge": "Handling large FAQ datasets efficiently.",
        "solution": "Implemented ChromaDB for fast vector search and persistent storage."
      },
      {
        "challenge": "Ensuring API key security.",
        "solution": "Used dotenv to manage environment variables and hide sensitive credentials."
      }
    ],
    "technologies": [
      "Python",
      "LangChain",
      "Google Gemini API",
      "HuggingFace Embeddings",
      "ChromaDB",
      "Streamlit"
    ],
    "skills": [
      "Vector Databases",
      "Semantic Search",
      "LLM Integration",
      "Prompt Engineering",
      "Interactive UI Development"
    ],
    "githubUrl": "https://github.com/kushalmittal04/specific_qa_chatbot",
    "liveUrl": null,
    "images": [
      {
        "url": "/images/projects/qa_chatbot/screenshot1.png",
        "dataAiHint": "Streamlit chatbot interface"
      },
      {
        "url": "/images/projects/qa_chatbot/screenshot2.png",
        "dataAiHint": "Chroma vector database flow"
      }
    ],
    "videoUrl": null,
    "category": [
      "AI",
      "Chatbot",
      "LLM"
    ],
    "isFeatured": true
  },
  {
    "id": 4,
    "slug": "portfolio-website",
    "name": "Personal Portfolio Website",
    "tagline": "A modern, full-stack portfolio website showcasing my skills, projects, and achievements.",
    "overview": "This is a modern, full-stack personal portfolio website built with Next.js and Tailwind CSS. It showcases my skills, professional experience, projects, and credentials in a clean and structured manner. The site is designed to be scalable, maintainable, and visually engaging, serving as a central hub for my work and achievements.",
    "features": [
      "Dynamic page structure for Home, About, Experience, Projects, Credentials, Education, Profiles, and Contact.",
      "Multi-theme support with Light and Dark themes.",
      "Responsive design optimized for all devices.",
      "Filterable project gallery with detailed description pages.",
      "Functional contact form with Nodemailer integration."
    ],
    "challenges": [
      {
        "challenge": "Managing content updates without affecting core logic.",
        "solution": "Implemented data-driven content using JSON files under /src/data for separation of concerns."
      },
      {
        "challenge": "Ensuring consistent UI/UX across multiple themes.",
        "solution": "Used ShadCN UI components with Tailwind CSS and Next-Themes for theming."
      },
      {
        "challenge": "Maintaining accessibility and performance.",
        "solution": "Followed best practices like semantic HTML, ARIA attributes, and Next.js App Router with server components."
      }
    ],
    "technologies": [
      "Next.js",
      "React",
      "TypeScript",
      "ShadCN UI",
      "Tailwind CSS",
      "Nodemailer",
      "Vercel"
    ],
    "skills": [
      "Frontend Development",
      "Full-Stack Development",
      "UI/UX Design",
      "Responsive Web Design",
      "Theming & Styling"
    ],
    "githubUrl": "https://github.com/kushalmittal04/portfolio",
    "liveUrl": "https://kushalmittal.vercel.app",
    "images": [
      {
        "url": "/images/projects/portfolio_website/screenshot1.png",
        "dataAiHint": "Portfolio homepage"
      },
      {
        "url": "/images/projects/portfolio_website/screenshot2.png",
        "dataAiHint": "Project gallery page"
      }
    ],
    "videoUrl": null,
    "category": ["Web Development", "Portfolio"],
    "isFeatured": true
  },
  {
    "id": 5,
    "slug": "rawg-gamehub",
    "name": "GameHub using RAWG API & Clerk",
    "tagline": "A responsive game discovery platform with authentication, filtering, and bookmarking features.",
    "overview": "This is a front-end web application built using React, designed to fetch and display game data from the RAWG Video Games Database API. It demonstrates the ability to build a responsive, feature-rich, and user-authenticated application using modern technologies.",
    "features": [
      "Main page layout with header, search bar, sidebar filters, and game grid.",
      "Filtering by categories, tags, release year, and popularity (rating).",
      "Real-time search bar with instant result updates.",
      "Game detail page with full description, screenshots, ratings, system requirements, and price info.",
      "Pagination for browsing large game datasets efficiently.",
      "Authentication using Clerk for sign-up, login, logout, and managing bookmarks.",
      "Redux-powered state management with persistence for bookmarks.",
      "Mobile-first responsive design with dark mode styling."
    ],
    "challenges": [
      {
        "challenge": "Efficiently handling large game datasets.",
        "solution": "Implemented pagination and filtering with Redux state management."
      },
      {
        "challenge": "Securing user authentication and bookmarks.",
        "solution": "Integrated Clerk authentication with protected routes and localStorage persistence."
      },
      {
        "challenge": "Maintaining responsive UI across devices.",
        "solution": "Used React-Bootstrap, Bootstrap, and custom CSS for adaptive layouts."
      }
    ],
    "technologies": [
      "React",
      "Redux Toolkit",
      "Clerk Auth",
      "React-Bootstrap",
      "Bootstrap",
      "Vanilla CSS"
    ],
    "skills": [
      "Frontend Development",
      "State Management",
      "Authentication",
      "Responsive Design",
      "API Integration"
    ],
    "githubUrl": "https://github.com/kushalmittal04/rawg-gamehub/",
    "liveUrl": "https://rawg-gamehub-mwjs.vercel.app/",
    "images": [
      {
        "url": "/images/projects/gamehub/screenshot1.png",
        "dataAiHint": "GameHub homepage"
      },
      {
        "url": "/images/projects/gamehub/screenshot2.png",
        "dataAiHint": "Game detail page"
      },
      {
        "url": "/images/projects/gamehub/screenshot3.png",
        "dataAiHint": "Bookmarks/library section"
      }
    ],
    "videoUrl": null,
    "category": ["Web Development", "Gaming"],
    "isFeatured": true
  },
  {
    "id": 6,
    "slug": "admission-management-system",
    "name": "Django Admission Management System",
    "tagline": "A full-featured admission form and management system with validation, reporting, and PDF generation.",
    "overview": "The Admission Management System is a Django-based web application designed to streamline student admissions. It features a dynamic admission form with validation, state-district auto-population, an advanced admin dashboard with preview and PDF printing, and reporting tools for analyzing admission statistics. The project is built with Django, PostgreSQL, and modern best practices for scalability and maintainability.",
    "features": [
      "Dynamic admission form with validations for mobile number, WhatsApp number, and pincode.",
      "Automatic district loading based on selected state and UT detection.",
      "Custom Django admin with preview and one-click PDF print button.",
      "Statistics dashboard with filters by state, district, course, and gender.",
      "PDF export for admission details using xhtml2pdf.",
      "PostgreSQL database integration for scalability.",
      "Reusable validators and clean, modular code structure."
    ],
    "challenges": [
      {
        "challenge": "Validating mobile numbers, WhatsApp numbers, and pincodes consistently across the app.",
        "solution": "Implemented regex validators in forms and suggested reusable model-level validators for consistent validation."
      },
      {
        "challenge": "Enabling dynamic district population based on selected state, including UTs.",
        "solution": "Created an AJAX-powered endpoint that auto-populates district options depending on state and UT logic."
      },
      {
        "challenge": "Providing user-friendly admin features for admission management.",
        "solution": "Added preview and print buttons in Django admin with custom admin views for PDF generation."
      },
      {
        "challenge": "Generating admission reports with useful breakdowns.",
        "solution": "Implemented StatsView with filtering and aggregation using Django ORM's Count and Q objects."
      }
    ],
    "technologies": [
      "Django",
      "PostgreSQL",
      "xhtml2pdf",
      "JavaScript (AJAX)",
      "Bootstrap",
      "HTML5/CSS3"
    ],
    "skills": [
      "Backend Development",
      "Form Validation",
      "Django Admin Customization",
      "Reporting & Analytics",
      "Database Design"
    ],
    "githubUrl": "https://github.com/kushalmittal04/admission_management_system",
    "liveUrl": null,
    "images": [
      {
        "url": "/images/projects/admission_management_system/form.png",
        "dataAiHint": "Admission form with dynamic state-district loading"
      },
      {
        "url": "/images/projects/admission_management_system/admin.png",
        "dataAiHint": "Custom Django admin with preview and PDF print button"
      },
      {
        "url": "/images/projects/admission_management_system/stats.png",
        "dataAiHint": "Statistics dashboard showing admission counts by course"
      }
    ],
    "videoUrl": null,
    "category": [
      "Web Development",
      "Django",
      "Database"
    ],
    "isFeatured": false
  },
  {
    "id": 7,
    "slug": "gmail-email-classifier",
    "name": "Gmail Email Classifier",
    "tagline": "A zero-shot learning powered Gmail email classifier with automatic labeling.",
    "overview": "The Gmail Email Classifier is a Python project that fetches emails from Gmail, classifies them into categories using zero-shot learning with Hugging Face transformers, and optionally applies labels directly in Gmail. It leverages Google OAuth for authentication, integrates with the Gmail API, and provides a structured workflow to analyze and organize emails efficiently.",
    "features": [
      "Fetch emails from Gmail using the Gmail API and OAuth 2.0 authentication.",
      "Classify emails into categories using zero-shot learning with Hugging Face transformers.",
      "Option to apply classification labels directly to emails in Gmail.",
      "Export classified email data into structured CSV files.",
      "Configurable date range for fetching emails."
    ],
    "challenges": [
      {
        "challenge": "Integrating Gmail API authentication securely.",
        "solution": "Configured OAuth 2.0 flow with credential storage in a secure directory excluded from version control."
      },
      {
        "challenge": "Classifying diverse email content without pre-labeled data.",
        "solution": "Used Hugging Face's zero-shot classification pipeline to dynamically assign labels without supervised training."
      },
      {
        "challenge": "Efficiently processing large sets of emails.",
        "solution": "Implemented progress tracking with tqdm and CSV exports for structured analysis."
      }
    ],
    "technologies": [
      "Python",
      "Google API Client",
      "Hugging Face Transformers",
      "PyTorch",
      "NLTK",
      "Pandas"
    ],
    "skills": [
      "API Integration",
      "Natural Language Processing",
      "Zero-Shot Learning",
      "OAuth 2.0 Authentication",
      "Data Preprocessing"
    ],
    "githubUrl": "https://github.com/kushalmittal04/email_classifier",
    "liveUrl": null,
    "images": [
      {
        "url": "/images/projects/gmail_classifier/1.png",
        "dataAiHint": "High-level workflow of Gmail email classification and labeling"
      },
      {
        "url": "/images/projects/gmail_classifier/2.png",
        "dataAiHint": "Google OAuth consent screen for Gmail API access"
      },
      {
        "url": "/images/projects/gmail_classifier/3.png",
        "dataAiHint": "Sample CSV output with classified emails and labels"
      },
      {
        "url": "/images/projects/gmail_classifier/4.png",
        "dataAiHint": "Sample CSV output with classified emails and labels"
      }
    ],
    "videoUrl": "https://www.youtube.com/embed/1HHhCkQsaKM",
    "category": [
      "ML",
      "NLP",
      "Automation"
    ],
    "isFeatured": false
  },
  {
    "id": 8,
    "slug": "atliq-tshirts-database-qa",
    "name": "AtliQ T-Shirts Database Q&A",
    "tagline": "An interactive Streamlit app powered by LangChain and Gemini that answers natural language queries over a MySQL retail database.",
    "overview": "The AtliQ T-Shirts Database Q&A project allows users to query a retail database using natural language. It integrates LangChain with Google’s Gemini LLM to dynamically generate SQL queries, fetch results from MySQL, and display them in a user-friendly Streamlit interface. The project also features a custom discount-aware agent for accurate revenue and pricing calculations.",
    "features": [
      "Ask natural language questions about stock, sales, discounts, and inventory.",
      "Streamlit interface for real-time Q&A with a retail database.",
      "LangChain SQL Agent integration with Gemini for dynamic query generation.",
      "Custom prefix logic for accurate discount and revenue calculations.",
      "Secure environment variable management with dotenv for API keys and DB credentials."
    ],
    "challenges": [
      {
        "challenge": "Generating accurate SQL queries from natural language with complex discount logic.",
        "solution": "Implemented a discount-aware agent with strict step-by-step SQL instructions to ensure correct revenue calculations."
      },
      {
        "challenge": "Ensuring secure database access without exposing credentials.",
        "solution": "Stored sensitive information in a `.env` file and a separate `database_credentials` module excluded from version control."
      },
      {
        "challenge": "Making results interpretable for end users in a simple interface.",
        "solution": "Used Streamlit to build a clean and interactive front-end for displaying query answers."
      }
    ],
    "technologies": [
      "Python",
      "LangChain",
      "Google Gemini LLM",
      "Streamlit",
      "MySQL",
      "SQLAlchemy",
      "dotenv"
    ],
    "skills": [
      "LLM-Powered Applications",
      "LangChain Agent Development",
      "SQL Query Generation",
      "Streamlit App Development",
      "Database Integration"
    ],
    "githubUrl": "https://github.com/kushalmittal04/retail_insights_generator",
    "liveUrl": null,
    "images": [
      {
        "url": "/images/projects/atliq_tshirts/1.png",
        "dataAiHint": "Streamlit interface showing a user query and database answer"
      },
      {
        "url": "/images/projects/atliq_tshirts/2.png",
        "dataAiHint": "Workflow diagram of natural language input → SQL query generation → database results"
      },
      {
        "url": "/images/projects/atliq_tshirts/3.png",
        "dataAiHint": "Discount-aware SQL calculation logic for revenue estimation"
      }
    ],
    "videoUrl": "https://www.youtube.com/embed/VOu-QYyEBjk",
    "category": [
      "AI",
      "Database",
      "LLM"
    ],
    "isFeatured": false
  }  
]
